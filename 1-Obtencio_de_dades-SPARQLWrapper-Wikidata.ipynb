{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657e8428",
   "metadata": {},
   "source": [
    "## Obtenció de dades *Wikidata* amb SPARQL\n",
    "\n",
    "Llibreries Python utilitzades:\n",
    "* Pandas v1.5.0\n",
    "* SPARQLWrapper v2.0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SPARQL online queries: https://query.wikidata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462fae1",
   "metadata": {},
   "source": [
    "### Configuració\n",
    "\n",
    "* Imports\n",
    "* Directori de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a46ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importem llibreires necessàries\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "\n",
    "# !pip install sparqlwrapper\n",
    "\n",
    "# Directori per gruardar les dades\n",
    "DATA = \"data/wikipedia/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e9c8e",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Definim les següients funcions:\n",
    "\n",
    "* create_sparqlwrapper() => SPARQLWrapper()\n",
    "* sparql_query(sparql, query) => time, results, sparql\n",
    "* convert_to_dataframe(results, cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94cb96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparqlwrapper():\n",
    "    \"\"\"Create SPARQLWrapper object\"\"\"\n",
    "    \n",
    "    \n",
    "    WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "    SPARQL_USER_AGENT = 'nurasakiBot/0.0 (nurasaki@gmail.com)'\n",
    "    \n",
    "    # Create SPARQLWrapper\n",
    "    sparql = SPARQLWrapper(WIKIDATA_ENDPOINT, agent=SPARQL_USER_AGENT)\n",
    "    \n",
    "    print(\"Creating SPARQLWrapper:\")\n",
    "    print(\"===\"*15)\n",
    "    print(\"Endpoint:\", sparql.endpoint) \n",
    "    print(\"User-Agent:\", sparql.agent) \n",
    "    \n",
    "    return sparql\n",
    "\n",
    "\n",
    "\n",
    "def sparql_query(sparql, query):\n",
    "    \"\"\"\n",
    "    Executa query a: \"https://query.wikidata.org/sparql\n",
    "    Retorna: temps, resultats\n",
    "    \"\"\"\n",
    "    \n",
    "    init = datetime.now()\n",
    "\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    # sparql.setMethod(method)\n",
    "\n",
    "    # sparql.setTimeout(300)  # 5 minutes\n",
    "    # https://python.hotexamples.com/examples/SPARQLWrapper/SPARQLWrapper/setTimeout/python-sparqlwrapper-settimeout-method-examples.html\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    return datetime.now()-init, results, sparql\n",
    "\n",
    "\n",
    "def convert_to_dataframe(results, cols=None):\n",
    "    \"Parse SPARQL query results in JSON format to DataFrame\"\n",
    "    \n",
    "    # cols = ['item','dateOfBirth', 'gender', 'profession']\n",
    "    bindings = results['results']['bindings']    \n",
    "    if len(bindings) > 0:\n",
    "        if cols is None:\n",
    "            cols = list(bindings[0].keys())\n",
    "    \n",
    "        df = pd.DataFrame([[r[col]['value'] for col in cols] for r in bindings], columns=cols)\n",
    "    else:\n",
    "        df = None    \n",
    "    \n",
    "    return len(bindings), df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d34c4",
   "metadata": {},
   "source": [
    "### Get Wikidata persons with professions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6379b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SCRAP = DATA + \"raw_persons_professions/\"\n",
    "if not os.path.exists(DATA_SCRAP):\n",
    "    os.makedirs(DATA_SCRAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23bf8652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SPARQLWrapper:\n",
      "=============================================\n",
      "Endpoint: https://query.wikidata.org/sparql\n",
      "User-Agent: nurasakiBot/0.0 (nurasaki@gmail.com)\n"
     ]
    }
   ],
   "source": [
    "# Create SPARQLWrapper object\n",
    "sparql = create_sparqlwrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e14ab",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0be93d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create raw SPARQL queries\n",
    "\n",
    "# P31  property:  instance of\n",
    "# Q5   class:     people\n",
    "# P21  property:  gender\n",
    "# P569 property:  date of birth\n",
    "# P106 property:  occupation or profession\n",
    "# Q28640 profession (Q28640) => occupation requiring specialized training\n",
    "\n",
    "PREFIX = \"\"\"\n",
    "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "\"\"\"\n",
    "\n",
    "select_str = \"SELECT ?person ?dateOfBirth ?gender ?profession\"\n",
    "where_str = \"\"\"\n",
    "WHERE {{\n",
    "    ?person wdt:P31 wd:Q5;\n",
    "            wdt:P21 ?gender;\n",
    "            wdt:P106 ?profession;\n",
    "            wdt:P569 ?dateOfBirth. hint:Prior hint:rangeSafe true.\n",
    "    {}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Query optimitzation:\n",
    "# https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/query_optimization#Optimization_strategies\n",
    "# => wdt:P569 ?dateOfBirth. hint:Prior hint:rangeSafe true.\n",
    "\n",
    "# => FILTER(YEAR(?dateOfBirth) = 1978) => no és tan eficient\n",
    "# => FILTER(\"1978-00-00\"^^xsd:dateTime <= ?dateOfBirth && ?dateOfBirth < \"1979-00-00\"^^xsd:dateTime)\n",
    "filter_raw = 'FILTER(\"{}-00-00\"^^xsd:dateTime <= ?dateOfBirth && ?dateOfBirth < \"{}-00-00\"^^xsd:dateTime)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bebd36",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Loop years\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da5eaef1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time            len_df     years\n",
      "0:00:15.860     162891  1900-1905\n",
      "0:00:27.568     153439  1905-1910\n",
      "0:00:15.696     159626  1910-1915\n",
      "0:00:05.265     142406  1915-1920\n",
      "0:00:09.385     195338  1920-1925\n",
      "0:00:10.649     211507  1925-1930\n",
      "0:00:06.265     214035  1930-1935\n",
      "0:00:06.300     234945  1935-1940\n",
      "0:00:07.145     277282  1940-1945\n",
      "0:00:09.375     329757  1945-1950\n",
      "0:00:11.790     367323  1950-1955\n",
      "0:00:08.431     341862  1955-1960\n",
      "0:00:21.869     348138  1960-1965\n",
      "0:00:18.081     321332  1965-1970\n",
      "0:00:17.835     312860  1970-1975\n",
      "0:00:07.349     290884  1975-1980\n",
      "0:00:26.407     266487  1980-1985\n",
      "0:00:09.605     237564  1985-1990\n",
      "0:00:07.899     193533  1990-1995\n",
      "0:00:06.927     133818  1995-2000\n",
      "0:00:04.613     109072  2000-2005\n",
      "0:00:01.630       7040  2005-2010\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'time':<12}{'len_df':>10}{'years':>10}\")\n",
    "years_step = 5\n",
    "\n",
    "for year in range(1900, 2010, years_step):\n",
    "    \n",
    "    # Create filter string (with years) and query\n",
    "    filter_str = filter_raw.format(year, year+years_step)\n",
    "    query = f\"{PREFIX}{select_str}{where_str.format(filter_str)}\"\n",
    "\n",
    "    # Make query\n",
    "    timedelta, results, sparql = sparql_query(sparql, query)\n",
    "    bindings, df = convert_to_dataframe(results)\n",
    "\n",
    "    # Agrupem ja que algunes referències tenen més d'una 'dateOfBirth' (depèn de la font)\n",
    "    df = df.groupby(['person', 'gender', 'profession']).first().reset_index()\n",
    "      \n",
    "    # Save results DataFrame to DATA folder\n",
    "    file = DATA_SCRAP + f\"wiki_occupations_{year}.csv\"\n",
    "    if df is not None:\n",
    "        df.to_csv(file, index=False)\n",
    "    \n",
    "\n",
    "    print(f\"{str(timedelta)[:-3]:<12}{len(df):>10}  {year}-{year+years_step}\")\n",
    "    \n",
    "    # Sleep 20 seconds to prevent query-limits\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c22795",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Merge years and separate genders\n",
    "\n",
    "* male_id   = \"Q6581097\"\n",
    "* female_id = \"Q6581072\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "484177bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Concatenate all collected files in DATA folder\n",
    "# ========================================================================================\n",
    "df_years = pd.DataFrame()\n",
    "for file in os.listdir(DATA_SCRAP):\n",
    "    df_years = pd.concat([df_years, pd.read_csv(DATA_SCRAP+file)])\n",
    "    \n",
    "# Group by \"profession\", \"gender\"\n",
    "cols = [\"profession\", \"gender\", \"person\"]\n",
    "df_professions = df_years[cols].groupby(cols[:-1]).count().reset_index()\n",
    "\n",
    "ENTITY_ENDPOINT = 'http://www.wikidata.org/entity/'\n",
    "for col in cols[:-1]:\n",
    "    df_professions[col] = df_professions[col].str.replace(ENTITY_ENDPOINT, \"\", regex=False)\n",
    "\n",
    "\n",
    "# Filter \"male\" and \"female\"\n",
    "# ========================================================================================\n",
    "male_id, female_id = \"Q6581097\", \"Q6581072\"\n",
    "df_female = df_professions[df_professions.gender == female_id]\n",
    "df_male = df_professions[df_professions.gender == male_id]\n",
    "\n",
    "\n",
    "# Clean data\n",
    "# ========================================================================================\n",
    "# Remove unknown professions\n",
    "unk_endpoint = \"http://www.wikidata.org/.well-known/\"\n",
    "df_male = df_male[~df_male.profession.str.startswith(unk_endpoint)]\n",
    "df_female = df_female[~df_female.profession.str.startswith(unk_endpoint)]\n",
    "\n",
    "# Rename columns \n",
    "df_male = df_male[[\"profession\", \"person\"]].rename(columns={\"person\": \"male\"})\n",
    "df_female = df_female[[\"profession\", \"person\"]].rename(columns={\"person\": \"female\"})\n",
    "\n",
    "# Merge male/female datafraes\n",
    "df_profs = df_female.merge(df_male, left_on=\"profession\", right_on=\"profession\", how=\"outer\").fillna(0)\n",
    "\n",
    "# Convert dtypes to int\n",
    "for col in ['female', 'male']:\n",
    "    df_profs[col] = df_profs[col].astype('int')\n",
    "\n",
    "# Compute totals and female ratios\n",
    "df_profs[\"total\"] = df_profs[\"female\"] + df_profs[\"male\"]\n",
    "df_profs[\"female_ratio\"] = df_profs[\"female\"] / df_profs[\"total\"]\n",
    "\n",
    "\n",
    "# Save to CSV file\n",
    "# ========================================================================================\n",
    "df_profs.to_csv(DATA + 'wiki_occupations_by_gender_totals_1900-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7a6eb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get occupation labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06b9fc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa757d78",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read base CSV ocuupation file without \n",
    "profs_file = DATA + 'wiki_occupations_by_gender_totals_1900-2020.csv'\n",
    "\n",
    "if not os.path.exists(profs_file):\n",
    "    print(\"L'arxiu no existeix!\")\n",
    "    \n",
    "# Create DataFrame\n",
    "df_profs = pd.read_csv(profs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ba6cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Create SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cd2a323",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SPARQLWrapper:\n",
      "=============================================\n",
      "Endpoint: https://query.wikidata.org/sparql\n",
      "User-Agent: nurasakiBot/0.0 (nurasaki@gmail.com)\n"
     ]
    }
   ],
   "source": [
    "sparql = create_sparqlwrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60d75852",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parse_results(results, lang):\n",
    "    \"\"\"Parses SPARQL query of profession labels results to DataFrame.\"\"\"\n",
    "    \n",
    "    rows = []\n",
    "    for r in results['results']['bindings']:\n",
    "        rows.append([\n",
    "            r['occupation']['value'].replace(ENTITY_ENDPOINT ,\"\"), \n",
    "            r['occupationLabel']['value'], \n",
    "            r.get('occupationAltLabel', {'value':\"\"})['value']\n",
    "        ])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows, columns=[\"profession\", f'label_{lang}', f'altLabel_{lang}'])\n",
    "    \n",
    "    # Remove labels with occupation ID\n",
    "    df.loc[(df['profession']==df[f'label_{lang}']), f'label_{lang}'] = \"\"\n",
    "\n",
    "    return df.groupby('profession').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28be58db",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalan labels, time: 0:00:23.533303\n",
      "English labels, time: 0:00:21.696315\n"
     ]
    }
   ],
   "source": [
    "ENTITY_ENDPOINT = 'http://www.wikidata.org/entity/'\n",
    "query_base = PREFIX + \"\"\"\n",
    "SELECT ?occupation ?occupationLabel ?occupationAltLabel\n",
    "WHERE {{\n",
    "  {{?occupation wdt:P31 wd:Q28640 .}}\n",
    "    UNION\n",
    "  {{?occupation wdt:P31/wdt:P279* wd:Q28640 .}}\n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"{}\" . }}\n",
    "}}\n",
    "\"\"\"\n",
    "# Define base SPARQL query, where occupation entities and language are variables\n",
    "# wdt:P31 => Instance of\n",
    "# wdt:P279 => subclass of\n",
    "# wd:Q28640 => Profession\n",
    "\n",
    "\n",
    "# Creat DataFrame amb els resultats agrupats\n",
    "df_labels = pd.DataFrame()\n",
    "\n",
    "# Get Catalan Labels\n",
    "time, results, _ = sparql_query(sparql, query_base.format(\"ca\"))\n",
    "print(\"Catalan labels, time:\", time)\n",
    "df_labels = parse_results(results, \"ca\")\n",
    "\n",
    "# Get English Labels and merge results\n",
    "time, results, _ = sparql_query(sparql, query_base.format(\"en\"))\n",
    "print(\"English labels, time:\", time)\n",
    "df_labels = df_labels.merge(parse_results(results, \"en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d49f0e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_profs = df_profs.merge(df_labels, how=\"left\").fillna(\"\")\n",
    "df_profs.to_excel(\"data/wikipedia/wiki_top_10500_professions-raw.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (conda_tfg_transformers)",
   "language": "python",
   "name": "conda_tfg_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
